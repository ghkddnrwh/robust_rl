import enum
import gym
from copy import deepcopy
import numpy as np

import matplotlib.pyplot as plt
import tensorflow as tf
import random

import time

a = [[-500.0, -500.0, -500.0, -292.0, -398.0, -244.0, -270.0, -149.0, -190.0, -197.0, -219.0, -155.0, -268.0, -116.0, -173.0, -255.0, -222.0, -142.0, -306.0, -500.0, -218.0, -154.0, -166.0, -170.0, -149.0, -120.0, -159.0, -155.0, -202.0, -146.0, -169.0, -123.0, -207.0, -139.0, -331.0, -114.0, -186.0, -106.0, -155.0, -120.0], [-500.0, -500.0, -472.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -292.0, -500.0, -500.0, -500.0, -458.0, -466.0, -427.0, -307.0, -409.0, -229.0, -316.0, -198.0, -178.0, -159.0, -166.0, -228.0, -157.0, -142.0, -216.0, -156.0, -165.0, -159.0, -132.0, -179.0], [-500.0, -298.0, -500.0, -290.0, -343.0, -337.0, -493.0, -208.0, -316.0, -340.0, -282.0, -244.0, -192.0, -201.0, -188.0, -201.0, -182.0, -254.0, -144.0, -121.0, -206.0, -179.0, -152.0, -316.0, -163.0, -180.0, -147.0, -140.0, -115.0, -133.0, -143.0, -189.0, -125.0, -325.0, -168.0, -210.0, -107.0, -118.0, -169.0, -150.0], [-401.0, -428.0, -500.0, -500.0, -191.0, -189.0, -150.0, -186.0, -221.0, -129.0, -118.0, -133.0, -134.0, -157.0, -153.0, -128.0, -183.0, -205.0, -170.0, -217.0, -214.0, -192.0, -145.0, -174.0, -123.0, -142.0, -142.0, -171.0, -110.0, -134.0, -136.0, -131.0, -108.0, -139.0, -163.0, -156.0, -99.0, -198.0, -99.0, -103.0], [-500.0, -500.0, -500.0, -309.0, -248.0, -271.0, -209.0, -300.0, -472.0, -239.0, -403.0, -383.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0], [-500.0, -500.0, -500.0, -500.0, -477.0, -285.0, -310.0, -192.0, -207.0, -267.0, -195.0, -207.0, -181.0, -145.0, -125.0, -166.0, -124.0, -135.0, -132.0, -136.0, -124.0, -163.0, -241.0, -200.0, -159.0, -171.0, -153.0, -181.0, -188.0, -193.0, -157.0, -159.0, -177.0, -187.0, -319.0, -155.0, -215.0, -238.0, -263.0, -161.0], [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -398.0, -379.0, -237.0, -370.0, -250.0, -356.0, -130.0, -270.0, -198.0, -119.0, -214.0, -204.0, -122.0, -290.0, -126.0, -289.0, -126.0, -138.0, -143.0, -168.0, -136.0, -128.0, -124.0, -137.0, -105.0, -115.0, -182.0, -192.0, -109.0], [-500.0, -500.0, -500.0, -367.0, -500.0, -255.0, -500.0, -143.0, -138.0, -186.0, -143.0, -117.0, -194.0, -206.0, -140.0, -181.0, -163.0, -124.0, -126.0, -133.0, -130.0, -138.0, -160.0, -148.0, -149.0, -125.0, -118.0, -133.0, -247.0, -183.0, -120.0, -125.0, -149.0, -153.0, -137.0, -120.0, -90.0, -92.0, -131.0, -121.0], [-500.0, -500.0, -500.0, -500.0, -500.0, -445.0, -232.0, -225.0, -167.0, -131.0, -130.0, -144.0, -194.0, -138.0, -152.0, -137.0, -144.0, -128.0, -129.0, -199.0, -130.0, -133.0, -156.0, -170.0, -144.0, -168.0, -107.0, -139.0, -145.0, -160.0, -157.0, -192.0, -133.0, -279.0, -138.0, -195.0, -160.0, -143.0, -92.0, -92.0], [-500.0, -500.0, -500.0, -397.0, -352.0, -305.0, -406.0, -469.0, -302.0, -326.0, -249.0, -152.0, -139.0, -127.0, -171.0, -97.0, -204.0, -151.0, -164.0, -183.0, -163.0, -155.0, -157.0, -106.0, -152.0, -161.0, -132.0, -147.0, -165.0, -103.0, -128.0, -110.0, -133.0, -120.0, -109.0, -100.0, -120.0, -133.0, -117.0, -133.0], [-351.0, -363.0, -327.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0], [-367.0, -486.0, -490.0, -176.0, -149.0, -109.0, -164.0, -176.0, -134.0, -157.0, -178.0, -164.0, -168.0, -165.0, -118.0, -170.0, -151.0, -175.0, -88.0, -100.0, -122.0, -220.0, -128.0, -144.0, -203.0, -92.0, -127.0, -290.0, -140.0, -135.0, -319.0, -118.0, -125.0, -91.0, -94.0, -133.0, -113.0, -131.0, -137.0, -116.0], [-465.0, -454.0, -458.0, -258.0, -260.0, -281.0, -345.0, -217.0, -179.0, -246.0, -222.0, -226.0, -171.0, -128.0, -122.0, -151.0, -155.0, -120.0, -153.0, -226.0, -145.0, -135.0, -173.0, -193.0, -146.0, -251.0, -171.0, -119.0, -210.0, -255.0, -140.0, -227.0, -153.0, -121.0, -152.0, -104.0, -122.0, -130.0, -112.0, -147.0], [-500.0, -500.0, -500.0, -500.0, -281.0, -140.0, -262.0, -157.0, -159.0, -170.0, -161.0, -197.0, -138.0, -163.0, -150.0, -132.0, -199.0, -139.0, -141.0, -214.0, -260.0, -116.0, -150.0, -107.0, -124.0, -126.0, -123.0, -214.0, -127.0, -159.0, -182.0, -111.0, -99.0, -107.0, -106.0, -188.0, -89.0, -79.0, -100.0, -116.0], [-500.0, -500.0, -500.0, -500.0, -333.0, -340.0, -219.0, -299.0, -227.0, -394.0, -118.0, -303.0, -223.0, -206.0, -186.0, -190.0, -219.0, -189.0, -163.0, -211.0, -285.0, -228.0, -238.0, -169.0, -228.0, -254.0, -182.0, -160.0, -218.0, -159.0, -221.0, -158.0, -153.0, -149.0, -146.0, -145.0, -140.0, -165.0, -161.0, -155.0], [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -380.0, -281.0, -299.0, -315.0, -315.0, -177.0, -154.0, -256.0, -177.0, -188.0, -140.0, -163.0, -156.0, -142.0, -136.0, -142.0, -188.0, -120.0, -144.0, -161.0, -137.0, -147.0, -182.0, -161.0, -236.0, -119.0, -167.0, -129.0, -96.0, -135.0, -124.0, -151.0, -119.0, -127.0], [-455.0, -385.0, -445.0, -500.0, -406.0, -254.0, -214.0, -217.0, -500.0, -284.0, -312.0, -376.0, -327.0, -236.0, -255.0, -167.0, -185.0, -261.0, -253.0, -192.0, -273.0, -215.0, -172.0, -439.0, -139.0, -128.0, -161.0, -140.0, -157.0, -129.0, -151.0, -146.0, -137.0, -158.0, -180.0, -133.0, -150.0, -132.0, -113.0, -105.0], [-500.0, -500.0, -340.0, -500.0, -500.0, -219.0, -352.0, -212.0, -242.0, -263.0, -339.0, -220.0, -305.0, -183.0, -385.0, -284.0, -406.0, -385.0, -254.0, -286.0, -443.0, -313.0, -225.0, -202.0, -142.0, -211.0, -190.0, -159.0, -133.0, -168.0, -126.0, -192.0, -196.0, -182.0, -177.0, -231.0, -304.0, -222.0, -241.0, -167.0], [-500.0, -500.0, -500.0, -500.0, -210.0, -185.0, -307.0, -180.0, -186.0, -262.0, -500.0, -215.0, -222.0, -263.0, -467.0, -324.0, -328.0, -260.0, -241.0, -271.0, -176.0, -264.0, -224.0, -281.0, -242.0, -229.0, -168.0, -199.0, -188.0, -232.0, -224.0, -256.0, -377.0, -240.0, -256.0, -193.0, -171.0, -179.0, -192.0, -158.0], [-500.0, -500.0, -500.0, -378.0, -380.0, -214.0, -471.0, -436.0, -438.0, -195.0, -274.0, -192.0, -197.0, -221.0, -220.0, -164.0, -239.0, -158.0, -163.0, -283.0, -86.0, -162.0, -199.0, -180.0, -167.0, -107.0, -103.0, -141.0, -128.0, -124.0, -151.0, -104.0, -154.0, -120.0, -118.0, -106.0, -107.0, -178.0, -122.0, -132.0], [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -348.0, -500.0, -325.0, -231.0, -397.0, -296.0, -394.0, -302.0, -173.0, -135.0, -241.0, -245.0, -181.0, -269.0, -286.0, -260.0, -289.0, -147.0, -186.0, -154.0, -156.0, -128.0, -115.0, -167.0, -122.0, -151.0, -123.0, -174.0, -129.0, -206.0, -172.0, -500.0, -146.0, -163.0], [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -362.0, -224.0, -222.0, -282.0, -348.0, -180.0, -188.0, -144.0, -230.0, -163.0, -128.0, -160.0, -199.0, -182.0, -149.0, -141.0, -131.0, -113.0, -127.0, -119.0, -89.0, -142.0, -134.0, -117.0, -124.0, -115.0, -162.0, -140.0, -133.0, -123.0, -119.0], [-350.0, -500.0, -437.0, -500.0, -334.0, -500.0, -203.0, -213.0, -204.0, -212.0, -222.0, -422.0, -366.0, -242.0, -424.0, -242.0, -239.0, -262.0, -221.0, -129.0, -162.0, -216.0, -156.0, -156.0, -155.0, -153.0, -169.0, -124.0, -158.0, -140.0, -191.0, -121.0, -166.0, -160.0, -147.0, -161.0, -126.0, -165.0, -122.0, -113.0], [-420.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -383.0, -463.0, -500.0, -500.0, -450.0, -500.0, -500.0, -452.0, -425.0, -500.0, -500.0, -314.0, -405.0, -380.0, -346.0, -212.0, -399.0, -218.0, -299.0, -178.0, -426.0, -147.0, -228.0, -161.0, -119.0, -183.0, -189.0, -230.0], [-500.0, -500.0, -500.0, -500.0, -500.0, -468.0, -450.0, -483.0, -410.0, -266.0, -251.0, -205.0, -202.0, -309.0, -219.0, -305.0, -277.0, -161.0, -204.0, -255.0, -292.0, -208.0, -191.0, -164.0, -221.0, -117.0, -221.0, -148.0, -157.0, -143.0, -134.0, -156.0, -181.0, -149.0, -200.0, -160.0, -216.0, -141.0, -114.0, -144.0], [-500.0, -500.0, -336.0, -375.0, -382.0, -500.0, -500.0, -500.0, -327.0, -362.0, -230.0, -292.0, -295.0, -303.0, -245.0, -180.0, -353.0, -182.0, -353.0, -154.0, -118.0, -311.0, -167.0, -254.0, -151.0, -188.0, -205.0, -210.0, -166.0, -155.0, -155.0, -137.0, -165.0, -157.0, -103.0, -175.0, -143.0, -144.0, -120.0, -150.0], [-500.0, -500.0, -263.0, -193.0, -367.0, -245.0, -211.0, -204.0, -178.0, -242.0, -302.0, -187.0, -265.0, -380.0, -138.0, -159.0, -384.0, -264.0, -412.0, -465.0, -196.0, -191.0, -183.0, -129.0, -100.0, -169.0, -168.0, -157.0, -124.0, -162.0, -199.0, -167.0, -127.0, -154.0, -129.0, -129.0, -201.0, -180.0, -180.0, -192.0], [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -443.0, -481.0, -500.0, -333.0, -500.0, -500.0, -397.0, -500.0, -500.0, -246.0, -301.0, -405.0, -209.0, -335.0, -402.0, -331.0, -323.0], [-500.0, -500.0, -500.0, -500.0, -406.0, -278.0, -213.0, -228.0, -230.0, -383.0, -294.0, -194.0, -232.0, -184.0, -122.0, -141.0, -150.0, -153.0, -231.0, -182.0, -173.0, -292.0, -165.0, -288.0, -253.0, -194.0, -213.0, -378.0, -282.0, -348.0, -192.0, -403.0, -304.0, -500.0, -192.0, -228.0, -272.0, -123.0, -401.0, -168.0], [-500.0, -500.0, -500.0, -467.0, -328.0, -379.0, -303.0, -346.0, -338.0, -345.0, -412.0, -402.0, -500.0, -279.0, -304.0, -335.0, -323.0, -328.0, -296.0, -271.0, -450.0, -428.0, -325.0, -500.0, -346.0, -375.0, -476.0, -232.0, -230.0, -233.0, -193.0, -180.0, -238.0, -251.0, -261.0, -199.0, -246.0, -173.0, -182.0, -250.0]]
a = np.array(a)
plt.plot(a[0])
plt.plot(a[1])
plt.plot(a[2])
plt.plot(a[3])
plt.plot(a[4])
plt.show()

# random.seed(0)
# env = gym.make("Ant-v4")
# state, _ = env.reset(seed = 0)

# print(state)

# action = env.action_space.sample()
# state, _, _, _, _ = env.step(action)
# print(action)
# print(state)

# zero = 0
# one = 0

# logits = [[10.0, 1.0]]
# logits = np.array(logits)
# for i in range(10000):
#     action = tf.random.categorical(logits, 1)
#     if action == 0:
#         zero+=1
#     else:
#         one+=1

# print(zero / (zero + one))
# print(np.array(action)[0, 0])
# print(action)


random.seed(0)

env = gym.make("Ant-v4")
state, _ = env.reset(seed = 0)

print(state)

action = env.action_space.sample()
state, _, _, _, _ = env.step(action)

print(action)
print(state)

print("Done")

# state_record = []
# pess_state_record = []

# # pess_env = deepcopy(env)
# pess_env = gym.make(env_name)

# env.reset(seed = seed)
# for i in range(10):
#     state, _, _, _, _ = env.step(0)
#     state_record.append(state)

# env.reset(seed = seed)
# for i in range(10):
#     print(state[0])
#     pess_env.reset()
#     exact_state = env.get_exact_state()
#     pess_env.set_state(exact_state)
#     # env.set_state(exact_state)
#     state, _, _, _, _ = env.step(0)
#     exact_state1 = env.get_exact_state()
#     pess_state, _, _, _, _ = pess_env.step(1)
#     exact_state2 = env.get_exact_state()

#     if(exact_state1 != exact_state2):
#         print("Something Wrong")


#     if(state[0] == pess_state[0]):
#         print("Same State")
#     else:
#         print("Different State")


#     pess_state_record.append(state)

# # print(state_record)
# # print(pess_state_record)
# state_record = np.array(state_record)
# pess_state_record = np.array(pess_state_record)
# if(state_record == pess_state_record).all():
#     print("Same")
# else:
#     print("Different")



# state_same_count = [0, 0, 0, 0, 0, 0]
# same_count = 0
# reward_same_count = 0


# for i in range(10000):
#     env.reset(seed = i)
#     env.step(1)
#     env.step(1)
#     env.step(1)
#     next_state, reward, _, _, _ = env.step(0)
#     env.reset(seed = i)
#     env.step(1)
#     env.step(1)
#     env.step(1)
#     new_next_state, new_reward, _, _, _ = env.step(1)

#     if(next_state == new_next_state).all():
#         same_count += 1
#     if next_state[0] == new_next_state[0]:
#         state_same_count[0] += 1
#     if next_state[1] == new_next_state[1]:
#         state_same_count[1] += 1
#     if next_state[2] == new_next_state[2]:
#         state_same_count[2] += 1
#     if next_state[3] == new_next_state[3]:
#         state_same_count[3] += 1
#     # if next_state[4] == new_next_state[4]:
#     #     state_same_count[4] += 1
#     # if next_state[5] == new_next_state[5]:
#     #     state_same_count[5] += 1
#     if reward == new_reward:
#         reward_same_count += 1

# print(state_same_count)
# print(same_count)
# print(reward_same_count)






# env.seed(0)
# env.reset(seed = 0)

# print(env.get_exact_state())


# print(env.get_exact_state())

# print(next_state)

# print(env.action_space.sample())
# pess_env = gym.make(env_name)

# state, _ = env.reset()
# pess_env.reset()
# print(state)

# step = 0


# while(True):
#     exact_state = env.get_exact_state()
#     print("Exact State : ",exact_state)
#     pess_env.set_state(exact_state)

#     action = env.action_space.sample()
#     # env.render()
#     next_state, _, done, truncated, _ = env.step(action)
#     pess_next_state, _, _, _, _ = pess_env.step(action)

#     if np.mean((pess_next_state - next_state)**2) < 0.01:
#         print("step : ", step + 1)
#         # print("State : ", next_state)
#     else:
#         print("Not equal")
#         print("State : ", next_state)
#         print("Pess State : ", pess_next_state)
#         while(True):
#             x = 1

#     if done or truncated:
#         print("RESET")
#         state, _ = env.reset()
#         step = 0
#     else:
#         state = next_state
#         step += 1
    # print("Current State : ", state)
    # print("Action : ", action)
    # print("State : ", next_state)
    # print("Pess State : ", pess_next_state)
    # state = next_state
    # step += 1
    # time.sleep(1)

    # break
    